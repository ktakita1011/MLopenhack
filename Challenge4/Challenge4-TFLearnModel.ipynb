{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4: Deep Learning\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Clears the default graph stack and resets the global default graph.\n",
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gear_images_128\\axes : 0\n",
      "gear_images_128\\boots : 1\n",
      "gear_images_128\\carabiners : 2\n",
      "gear_images_128\\crampons : 3\n",
      "gear_images_128\\gloves : 4\n",
      "gear_images_128\\hardshell_jackets : 5\n",
      "gear_images_128\\harnesses : 6\n",
      "gear_images_128\\helmets : 7\n",
      "gear_images_128\\insulated_jackets : 8\n",
      "gear_images_128\\pulleys : 9\n",
      "gear_images_128\\rope : 10\n",
      "gear_images_128\\tents : 11\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils  import to_categorical\n",
    "import tensorflow as tf\n",
    "data_path = './gear_images_128'\n",
    "category = 0 # Category label\n",
    "labels = [] # Label strings\n",
    "x = [] # Image data\n",
    "y = [] # Labels for each image\n",
    "\n",
    "def prepare_dataset(file):    \n",
    "    try:\n",
    "        im = Image.open(file)\n",
    "        arr = np.array(im)\n",
    "        x.append(arr)\n",
    "        y.append(to_categorical(category, num_classes=12)) # if category is 1, then it returns [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "    except:\n",
    "        print(\"cannot add to dataset:\", file)\n",
    "\n",
    "# Loop all data and create dataset\n",
    "for dir in Path(data_path).iterdir():\n",
    "    labels.append(str(dir).split('/')[-1])\n",
    "    for file in dir.iterdir():\n",
    "        prepare_dataset(file)\n",
    "    print(dir, ':', category)\n",
    "    category += 1\n",
    "\n",
    "x = np.asarray(x,dtype=float) # Convert image list into array of float.\n",
    "x = x/255 # Make value between 0 to 1\n",
    "y = np.asarray(y,dtype=float)\n",
    "\n",
    "# Split data into 70% train and 30% test. \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "IMG_SIZE = 128\n",
    "LR = 1e-3\n",
    "\n",
    "# Input data shape is 4-D Tensor. [batch, height, width. channel]\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.5)\n",
    "convnet = fully_connected(convnet, 12, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.24054\u001b[0m\u001b[0m | time: 83.697s\n",
      "| Adam | epoch: 010 | loss: 0.24054 -- iter: 1472/1485\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.22424\u001b[0m\u001b[0m | time: 90.773s\n",
      "| Adam | epoch: 010 | loss: 0.22424 | val_loss: 0.27118 -- iter: 1485/1485\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME  =\"AdventureWorksModel-RegressionFirst\"\n",
    "model.fit({'input': x_train}, {'targets': y_train}, n_epoch=10, validation_set=({'input': x_test}, {'targets': y_test}), snapshot_step=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\p000524252\\jupyter\\Challenge4\\MODEL_NAME is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\p000524252\\jupyter\\Challenge4\\AdventureWorksModel.tflearn\n"
     ]
    }
   ],
   "source": [
    "model.load(\"AdventureWorksModel.tflearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9215070644577781]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[ 5  1  4  3  4  1  6  2  5  4  4  5 10  8  6  0 11  5  3  9  8  8  2  2\n",
      "  4  3  6  3 11  3  8 10  2 10  5  2  0  5 11  6  2  3  6  6  2  1  5  5\n",
      "  3  5  5  6  5  5  9  7  3  7  5  8  8  1  6  8  5  4  0  0  7  2  5  8\n",
      " 11  2  5 10  6  0  1 10  6  8  2  2  7  6  5  1  5  3  5  3 11 10  2  7\n",
      "  8  5  5  3  7 11  4  4  4  5  2  5  5  2 11 10  5  8  8  2  2  1  5  6\n",
      "  5  2  8  0 10  6 10  2  7 11  5  6  6  4  6  3  3  4  5  0  2  5  0  3\n",
      "  8  5 10  6  8  3  4 10  5  3  8  8  1 10  4  8  8  5  2 11 11  5  6  1\n",
      "  0  3 10  5  4  6  5  5  5  8  2  2  3  5  8  8  8  3  5 10  2  5  9  8\n",
      "  0 11  8  7 10  7 11  5 11  2  5 11  2  1  8 11 11  2  1  1  5  9 10  6\n",
      "  5  2  8  5  2  8  0  5  6  5  9  2 10  9 11 11  9  6  2  2  3  5  7  0\n",
      "  5  7  2 10  5 11  2  5  2  8  8  1  5 10  5 10 10 11  9  0  8  2  9  8\n",
      " 10  6  3  7  6  2  6  5  6  3 10 11  6  8  8  5  8  2  3  8 11  0  2  0\n",
      " 10  2  5  2  5 10  6  5 10  3  4  8  5  5  8 10  6  4  1  8  8  4  1  0\n",
      "  3  4  2  6 10  8  4  6  8  6  5  4  5  8  5  2  4  2  2  1 11  1  5  5\n",
      "  5  5  6  6  4  8  3 10  3  2  4  4  5  9  8  5 10  1  5  8  2  2 10  2\n",
      " 11  7  3  5  4  2  5  3  8  8  5  5  5  2  5  4  7  4  3 10  3 11  0  8\n",
      "  4  5  2  6  5  9  5  3  4 11  5  6  4 11  4  4  1  0  8 10  5  2 10  0\n",
      "  1 10  5  8  4  6  7  7  3 10  4  6  7  4  5  4  4  5  4  2  5  2  5 10\n",
      "  5  4  8  8  6  5  4  1  2  2  5  5  3  8  5  6  8  8  8  0  1  9  8  4\n",
      "  2  0  2  4  7  5  5  4 10  8  4  8  2  6  5  4  3  5 11  5  8  2  9  6\n",
      "  4 10  7  2  0  5  5  7  7  0  5  7  4  0  5  2  3  4 10  8  6 11  0  0\n",
      "  5  4  8  5  8 10  5 10  6  6  4  3  7  5  2  8  8  9  7  4  0  8  5  8\n",
      "  0 10  3  8  0  5  7  5  5  5  1  5  3  8  1  4  6  8  2  5 11  4  7  8\n",
      " 11  4  4  1  4  2  6  5  5  8  2  0 11  2 10  5  5  1  8  2  4  3  1  6\n",
      "  5  2  5  4  5  5  8  4  3  4  4  5  2  3  8 10  7  5  8 10  7  0  2  2\n",
      "  2  5  2  5 11  5  7  4  8  8  2  3  3  5  6  5  7  6  2  8  5  2  5 10\n",
      "  5  5  8  6 10  1  5  8  1  3  4  6  8]\n",
      "(637,)\n"
     ]
    }
   ],
   "source": [
    "y_test.shape\n",
    "print(y_test)\n",
    "y_test_np = np.argmax(y_test,1)\n",
    "print(y_test_np)\n",
    "print(y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5151639e-07 1.3538017e-05 3.9297065e-05 ... 2.0666688e-05\n",
      "  1.9951785e-06 1.8902468e-07]\n",
      " [5.1288862e-10 9.9990094e-01 4.7375690e-09 ... 2.0696189e-06\n",
      "  1.4698500e-06 1.4466321e-11]\n",
      " [6.8878758e-06 7.5989621e-05 6.5164233e-04 ... 4.4438293e-05\n",
      "  3.6412304e-05 7.5432780e-07]\n",
      " ...\n",
      " [4.3061766e-07 1.7510138e-03 2.6194425e-04 ... 1.2893711e-04\n",
      "  1.6912158e-07 2.5487620e-07]\n",
      " [1.4325716e-08 1.3526309e-06 5.3250536e-05 ... 4.0408759e-06\n",
      "  2.5896325e-08 5.8088881e-11]\n",
      " [4.3020293e-07 2.4297477e-05 1.9458799e-04 ... 2.5374376e-05\n",
      "  7.4143968e-06 6.4430640e-07]]\n",
      "[ 8  1  4  3  4  1  6  2  5  4  4  5 10  4  6  3 11  5  3  4  8  8  2  2\n",
      "  4  3  6  3 11  3  8 10  2 10  5  2  0  5 11  6  2  3  6  6  2  1  5  5\n",
      "  3  5  5  6  5  5 10  7  3  7  5  8  8  1  6  8  8  4  0  0  7  2  5  8\n",
      " 11  2  5 10  6  0  1 10  6  8  0  2  7  6  4  1  5  3  5  3 11 10  2  7\n",
      "  8  5  5  3  7 11  4  4  4  5  2  5  5  2 11 10  5  8  8  2  2  1  5  6\n",
      "  7  2  8  0 10  6 10  2  7  0  5  6  6  4  6  3  3  4  5  0  2  5  0  3\n",
      "  8  5 10  6  8  3  4 10  5  3  8  8 11 10  4  8  8  5  2 11 11  5  6  1\n",
      "  0  3 10  5  4  6  5  8  5  8  2  2  3  5  5  8  4  3  8 10  2  5  9  8\n",
      "  3 11  8  4 10  7 11  4 11  2  5 11  2  1  8  0 11  2  1  1  8  9 10  6\n",
      "  5  2  8  5  2  4  0  5  6  5  9  2 10  9 11 11  9  6  2  2  3  5  7  0\n",
      "  8  7  2 10  5 10  2  5  1  8  8  1  5 10  5 10 10 11  0  0  8  2  9  4\n",
      " 10  6  3  7  6  2  6  5  6  3 10 11  6  8  8  5  8  2  3  8 11  0  2  0\n",
      " 10  2  5  2  5 10  6  5 10  3  4  8  5  5  8 10  6  4  1  8  8  4  1  0\n",
      "  3  4  2  6 10  8  4  6  8  6  5  4  5  8  5  2  4  2  2  1 11  1  5  5\n",
      "  5  5  6  6  4  8  3 10  3  2  4  4  5  9  8  5 10  1  5  8  2  2 10  2\n",
      " 11  4  3  5  4  2  8  3  5  8  8  8  5  2  5  4  7  4  3 10  3 11  0  8\n",
      "  4  5  2  6  5  9  5  3  4 11  5  6  4 11  4  4  1  0  5 10  5  2 10  0\n",
      "  1 10  5  8  4  6  7  7  3 10  4  6  7  4  5  4  4  5  4  2  5  2  5 10\n",
      "  5  4  8  5  6  5  4  1  2  2  5  5  3  8  5  6  8  8  8  0  1  2  8  4\n",
      "  2  2  2  4  7  5  8  4  4  8  4  8  2  6  5  4  3  5 11  5  8  2  2  6\n",
      "  4 10  7  2  0  5  5  7  7  0  5  7  4  0  5  2  3  4 10  8  6 11  0  0\n",
      "  5  4  5  5  8 10  5 10  6  6  4  3  7  5  2  8  5  9  7  4  0  8  5  8\n",
      "  0 10  3  8  0  5  2  8  5  5  1  5  3  5  1  4  6  8  2  5 11  4  7  8\n",
      " 11  4  4  1  4  2  6  5  8  5  2  0 11  2 10  8  5  1  8  2  4  3  1  6\n",
      "  8  2  5  4  5  5  8  4  3  4  4  5  2  3  8 10  7  5  5 10  4  0  2  2\n",
      "  2  8  2  5 11  5  7  4  8  8  2  3  3  5  6  5  7  6  2  8  5  2  5 10\n",
      "  5  5  8  6 10  1  5  8  1  3  4  6  8]\n",
      "(637,)\n"
     ]
    }
   ],
   "source": [
    "y_predict.shape\n",
    "print(y_predict)\n",
    "y_pre_np = np.argmax(y_predict,1)\n",
    "print(y_pre_np)\n",
    "print(y_pre_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28,   0,   1,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  28,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1],\n",
       "       [  1,   1,  75,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,  45,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  63,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   2, 114,   0,   1,  15,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  52,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   0,   3,   0,   0,  26,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   4,   9,   0,   0,  70,   0,   0,   0],\n",
       "       [  1,   0,   2,   0,   1,   0,   0,   0,   0,   9,   1,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   0,  47,   0],\n",
       "       [  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  30]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test_np,y_pre_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        31\n",
      "           1       0.97      0.97      0.97        29\n",
      "           2       0.95      0.97      0.96        77\n",
      "           3       0.96      1.00      0.98        45\n",
      "           4       0.85      1.00      0.92        63\n",
      "           5       0.93      0.86      0.89       132\n",
      "           6       1.00      1.00      1.00        52\n",
      "           7       0.96      0.87      0.91        30\n",
      "           8       0.82      0.84      0.83        83\n",
      "           9       1.00      0.64      0.78        14\n",
      "          10       0.96      0.98      0.97        48\n",
      "          11       0.97      0.91      0.94        33\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       637\n",
      "   macro avg       0.94      0.91      0.92       637\n",
      "weighted avg       0.92      0.92      0.92       637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_np, y_pre_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DNN' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-879486ade4e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconfusionMat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DNN' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "predict_classes = model.predict_classes(x_test, batch_size=1)\n",
    "prediction = []\n",
    "prediction.append(y_predict)\n",
    "labels.append(y_test)\n",
    "confusionMat=tf.confusion_matrix(y_test,y_predict,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
